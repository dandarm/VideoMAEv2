Domanda (utente):
Voglio modificare il MedicanesTrackDataset per poter accettare un file CSV che contenga coordinate in pixel.
In più, serve un nuovo DataBuilder che crei questo CSV partendo dal builder esistente per la classificazione, mantenendo solo i video con label=1, trasferendo le coordinate, e scartando gli offsets.

Risposta (assistant):
Ok, prima scannerizzo il codice del dataset per capire la struttura attuale e come sono organizzati i builder. Poi apro tracking_dataset.py per implementare il supporto al CSV con coordinate in pixel.

Contesto tecnico (analisi assistant):

Il dataset MedicanesTrackDataset estende MedicanesClsDataset.

Attualmente richiede colonne lon e lat nel CSV (coordinate geografiche).

Il costruttore verifica la presenza delle colonne e restituisce coordinate come tensore [lon, lat].

I file del dataset includono:

tracking_dataset.py → definisce MedicanesTrackDataset (usa colonne lon, lat).

data_manager.py → gestisce offsets e crea dataframe master, con colonne tile_offset_x, tile_offset_y, lat, lon.

build_dataset.py → contiene i builder esistenti, utilizzati anche per la classificazione.

In dataset/data_manager.py c’è un dizionario tipi che include x_pix, y_pix.

load_master_df(...) legge anche x_pix, y_pix nel master_df.

Il tracking dataset però non usa ancora x_pix, y_pix: usa lon, lat.
(Rif.: dataset/data_manager.py)

Come adattare MedicanesTrackDataset per usare pixel invece di lon/lat?

(Proposta operativa)

Aggiungere opzioni per i nomi delle colonne pixel (es. x_col='x_pix', y_col='y_pix') oppure auto-detect: se sono presenti x_pix/y_pix, usare quelli; altrimenti fallback su lon/lat.

Uniformare l’output: coords = tensor([x_pix, y_pix]) quando in modalità pixel, altrimenti [lon, lat].

Mantenere il filtro label==1.
(Luogo: dataset/tracking_dataset.py)

Che cosa deve fare il nuovo DataBuilder per generare il CSV “tracking in pixel”?

R5. (Proposta operativa)

Partire dal builder esistente per la classificazione (BuildDataset in data_manager.py / funzioni in build_dataset.py).

Costruire/leggere il master_df (già contiene x_pix, y_pix quando disponibili).

Filtrare a label == 1.

Scartare gli offsets (tile_offset_x, tile_offset_y) e altre colonne non necessarie.

Conservare path, label, x_pix, y_pix (+ eventuali campi minimi richiesti).

Esportare il CSV finale (es. create_final_df_csv(...)).
(Rif.: dataset/data_manager.py, dataset/build_dataset.py)

(Aspetti pratici/validazioni)
Quali verifiche conviene aggiungere?

R6. (Checklist)

Validare la presenza di colonne richieste (in modalità pixel: x_pix, y_pix; in modalità geo: lon, lat).

Garantire che path sia risolvibile (assoluto o relativo a data_root).

Gestire cartelle con meno di clip_len frame ripetendo l’ultimo frame (già presente in MedicanesClsDataset).

Mantenere l’ordine delle trasformazioni/normalizzazioni come nel dataset di classificazione per coerenza.



Dove intervenire per far comparire le coordinate in pixel nel CSV finale dei video?

R1. La funzione attuale create_final_df_csv(df_in, output_dir) (in dataset/build_dataset.py) genera solo path, start, end, label. Va creata una variante (es. create_final_tracking_csv) che includa anche x_pix, y_pix (se presenti nel df_in) e che scarti gli offsets (tile_offset_x, tile_offset_y) non necessari nel CSV di tracking.

Come vengono calcolate/ottenute le coordinate pixel a partire da lon/lat?

R2. In dataset/build_dataset.py ci sono utilità:

get_lon_lat_grid_2_pixel(...) + trova_indici_vicini(...) per ricavare px, py vicini alla posizione geospaziale,

get_cyclone_center_pixel(lat, lon, image_h=420) che restituisce (px, py) (con flip su y),

inside_tile_faster(x_pix, y_pix, tile_x, tile_y, ...) per verifiche di inclusione.

Queste funzioni supportano l’uso coerente di x_pix, y_pix nella pipeline.

Quali colonne/tipi sono già previste per lavorare con pixel?

R3. In dataset/data_manager.py, diz_types prevede x_pix e y_pix oltre a lat, lon e agli offsets (tile_offset_x, tile_offset_y). Questo indica che il master_df può (o dovrebbe) contenere x_pix, y_pix, quindi sono utilizzabili in fase di export.

Come viene costruito il video dataframe prima del CSV?

R4. create_df_video_from_master_df(...):

raggruppa per periodi contigui (get_gruppi_date),

raggruppa per offsets (group_df_by_offsets(df)),

costruisce i blocchi video con fine all’ora intera tramite create_tile_videos_last_frame_integer_hour(...),

produce righe con: video_id, tile_offset_x, tile_offset_y, path, label, start_time, end_time, orig_paths.

Come si genera oggi il CSV finale e cosa manca per il tracking?

R5. create_final_df_csv(df_in, output_dir):

crea path assoluti (prefix output_dir + path relativo della cartella con i 16 frame),

imposta start=1, end=16,

seleziona solo ['path', 'start', 'end', 'label'].

Per il tracking occorre:

filtrare label==1 prima dell’export,

inserire x_pix, y_pix (se presenti nel df),

rimuovere dal CSV colonne superflue come tile_offset_x, tile_offset_y.

Qual è la logica core per la costruzione delle tile/video utile al tracking?

R6.

Generazione offsets: calc_tile_offsets(...).

Estrazione tile dai frame: save_single_tile(...) / create_and_save_tile_from_complete_df(...).

Costruzione blocchi video: create_tile_videos_last_frame_integer_hour(...) (1h20’ di dati, con step a ore intere).

(Opzionale) Marcatura tile adiacenti a positive: mark_neighboring_tiles(...).

(Opzionale) Indice di nuvolosità per tile/video: funzioni cloud_idx e affini.

Cosa deve fare il nuovo DataBuilder dedicato al tracking in pixel?

R7.

Partire dal master_df (che può contenere x_pix, y_pix),

creare il df_video con le funzioni esistenti,

filtrare label==1,

selezionare colonne minime: path, label, x_pix, y_pix (+ eventuali temporali se servono, es. end_time),

esportare con una funzione ad hoc (variante di create_final_df_csv) che non reintroduca offsets.

Come viene usato il dataset di tracking nel training?

R1.
Nel file tracking.py la funzione launch_tracking crea due dataset:
train_dataset = MedicanesTrackDataset(args.train_path, data_root=args.data_root, clip_len=args.num_frames)
test_dataset  = MedicanesTrackDataset(args.test_path,  data_root=args.data_root, clip_len=args.num_frames)

Questi dataset vengono poi passati a DataLoader con DistributedSampler.
Il training e la validazione usano train_one_epoch ed evaluate (definiti in engine_for_tracking.py).

Qual è la funzione di engine_for_tracking.py?

R2.

train_one_epoch: esegue un ciclo di training, riceve (samples, target, _) dal dataset, passa samples al modello, calcola la loss con target e aggiorna i pesi.

evaluate: simile ma in modalità torch.no_grad(), serve per la validazione.
Entrambe assumono che il target sia direttamente confrontabile con l’output del modello, quindi già in coordinate (lon/lat o x_pix/y_pix).

Che tipo di loss viene usata per il tracking?

R3.
In tracking.py si definisce:

criterion = nn.MSELoss()

Quindi il modello viene addestrato a regredire due valori continui (coordinate), minimizzando l’errore quadratico medio.

Qual è il numero di output previsto dal modello di tracking?

R4.
In launch_tracking:

args.nb_classes = 2  # two regression outputs: lon and lat

Il modello creato da create_tracking_model avrà quindi 2 neuroni in output, corrispondenti alle coordinate target.

Come deve quindi essere organizzato il CSV per il tracking?

R5.
Il CSV deve contenere:

path → cartella del video (16 frame),

x_pix, y_pix (oppure lon, lat) del centro ciclone nell’ultimo frame,

opzionalmente start, end o timestamp, se richiesti dalla pipeline.

Dato che la loss è MSELoss, MedicanesTrackDataset deve leggere dal CSV due colonne numeriche (coordinate) e restituirle come target tensor di shape [2].

Quali modifiche vanno fatte a MedicanesTrackDataset?

R6.

Permettere di specificare quali colonne usare come coordinate (x_pix, y_pix o lon, lat).

Caricare le coordinate dal CSV e restituirle come target.

Non serve più il label binario (come nel dataset di classificazione), perché qui il training è supervisionato con regressione.


Come cambia MedicanesTrackDataset rispetto a prima?

R1.
Ora accetta due modalità di coordinate nel CSV:

Pixel: colonne x_pix, y_pix (default).

Geografiche: colonne lon, lat (fallback).
Se esiste la colonna label, filtra automaticamente solo le righe con label == 1. In __getitem__ ritorna (video, coords, folder_path), dove coords è un tensore [2] con (x,y) in pixel oppure (lon,lat) in geo, a seconda delle colonne presenti.

Cosa viene richiesto al CSV del tracking, quindi?

R2.
Obbligatorio: path (cartella del video) + coppia di coordinate (x_pix,y_pix oppure lon,lat).
Opzionale: label (se presente, il dataset tiene solo label==1).

Come vengono scelti i blocchi video nel builder “ora tonda”?

R3.
La funzione che crea i video con ultimo frame all’ora intera (HH:00):

Scorre gli indici dove datetime è esattamente su ora intera.

Per ciascun indice end_idx, costruisce un blocco di num_frames (es. 16) risalendo a start_idx = end_idx - (num_frames - 1).

Scarta blocchi se non c’è sufficiente storia o se l’ultimo minuto non è 00.

Come viene assegnata la label del video in quel builder?

R4.
Conta quante righe del blocco hanno label==1; se num_pos_labels > num_frames/3 allora assegna label=1, altrimenti 0.

Cosa produce labeled_tiles_from_metadatafiles_maxfast?

R5.
Pipeline vettoriale che:

fa il prodotto cartesiano immagini × offset;

fa merge con i track su ora arrotondata;

calcola inside tile;

aggrega i “colpiti” in liste (x_pix, y_pix, source) e prende id_cyc_unico, start_time, end_time;

unisce con tutte le combinazioni per ottenere anche i negativi (label a 0);

fa fill: liste vuote per tile senza hit, id_cyc_unico=0, start_time/end_time=NaT.
Ritorna un DataFrame tipizzato con colonne: path, datetime, tile_offset_x/y, label, x_pix, y_pix, source, id_cyc_unico, start_time, end_time.

A cosa serve create_and_save_tile_from_complete_df?

R6.
Dato un DF finale di video, crea le cartelle dei video e salva/croppa i 16 frame per ciascun video nella sottocartella .../img_00001.png … img_00016.png, rispettando gli offset (tile_offset_x/y). Supporta overwrite

Come raggruppa e bilancia nel tempo?

R7.

get_gruppi_date: crea gruppi temporali contigui (nuovo gruppo se gap > 60 min).

balance_time_group: stampa conteggi e bilancia i video selezionando un sottoinsieme dei negativi per pareggiare i positivi.

Come etichetta cartelle già pronte con i track?

R8.
label_subfolders_with_cyclones_df:

per ogni subfolder, controlla i dt dei frame contro i track raggruppati per (anno, mese, giorno, ora);

se qualche frame ha un centro dentro la tile → label=1, altrimenti 0;

costruisce un DF/CSV con colonne: path, start, end, label, start_time, end_time (nota: internamente usa chiave folder e poi costruisce il DF con colonna path).


Novità principali

BuildTrackingDataset (estende BuildDataset)

Scopo: generare un CSV per il tracking con coordinate pixel del centro ciclone all’ultimo frame del video.

Filtra opzionalmente solo i video positivi (label==1), senza includere offset nel CSV finale (“scarti gli offsets”).

Coordinate relative alla tile

Da master_df prendiamo le liste x_pix, y_pix sul frame finale (end_time) e ne estraiamo il primo valore (nel caso di più centri).

Convertiamo in coordinate relative alla tile:
x_rel = x_pix_last - tile_offset_x
y_rel = y_pix_last - tile_offset_y

Questo allinea i target con le immagini 224×224 (range atteso ≈ [0, 224)).

Output del CSV di tracking

Colonne: path, start, end, x_pix, y_pix

path: cartella del video (prefissata con output_dir)

start=1, end=num_frames (es. 16)

x_pix, y_pix: relative alla tile, float.

API nuove

create_tracking_df(output_dir, only_label_1=True, num_frames=16) -> DataFrame
Crea il DataFrame pronto per il tracking.

create_tracking_csv(output_dir, path_csv, only_label_1=True, num_frames=16)
Salva il CSV di tracking.

prepare_data(df_tracks, input_dir, output_dir, relabeling=False, is_to_balance=False)
Prepara master_df e df_video senza scrivere CSV di classificazione (replica il flusso di get_data_ready, con opzioni per relabeling, filtro nuvolosità e marcatura dei vicini).

MedicanesTrackDataset — reminder

Ora accetta pixel (x_pix,y_pix) o geo (lon,lat) e ritorna (video, coords, folder_path) con coords come tensore [2].


-------------------------------
from dataset.data_manager import BuildTrackingDataset

# 1) Prepara i DF (master_df + df_video) senza produrre CSV di classificazione
bt = BuildTrackingDataset()
bt.prepare_data(
    df_tracks=tracks_df,         # dataframe dei track (già caricato)
    input_dir="/path/immagini",  # immagini sorgente
    output_dir="/path/dataset"   # root dove vivono i video/tiles
)

# 2) Crea il CSV di tracking con coordinate pixel relative alla tile
bt.create_tracking_csv(
    output_dir="/path/dataset", 
    path_csv="/path/dataset/tracking.csv",
    only_label_1=True,     # tieni solo positivi
    num_frames=16
)
---------------------------------

Caricando poi il CSV con MedicanesTrackDataset (che leggerà x_pix,y_pix), avrai target già coerenti con la tile 224×224.
Se nel CSV compaiono sia label sia x_pix,y_pix, i negativi vengono esclusi quando only_label_1=True.
Se x_pix/y_pix sono liste, prendiamo il primo elemento (gestione multi-centro semplice; si può estendere in futuro).
Le trasformazioni d’immagine mantengono la dimensione 224×224, quindi le coordinate non vanno riscalate.

Perché il merge tra self.master_df e dfv?

df_video (dfv) ha il video-level: path, start_time, end_time, tile_offset_x/y, ecc.

Le coordinate del centro (x_pix, y_pix) sono frame-level in master_df (una riga per timestamp/tile).

Per ottenere la posizione del centro all’ultimo frame del video, bisogna unire dfv con master_df su:

end_time ↔ datetime

tile_offset_x, tile_offset_y
Così recuperiamo le x_pix/y_pix del frame finale, poi le convertiamo in relative alla tile sottraendo gli offsets (e gli offsets non entrano nel CSV).

Se in quel timestamp ci sono più centri nella stessa tile, al momento prendiamo il primo della lista; si può sostituire con regole diverse (es. “più vicino al centro tile”, media, ecc.).

prepare_data: tolti filtro clear-sky e mark neighboring.
Fatto. Ora BuildTrackingDataset.prepare_data(...) non applica più quei passaggi (erano utili alla classificazione, non al tracking).

Solo pixel, mai lat/lon.
Allineato. Il MedicanesTrackDataset ora richiede x_pix e y_pix nel CSV (se c’è label, filtra ==1, altrimenti usa tutto). Niente fallback a lon/lat.


Stato del codice (dove guardare)

dataset/data_manager.py

BuildTrackingDataset.create_tracking_df(...): merge su end_time/offset per pescare le coord. dell’ultimo frame; conversione a tile-relative; output: path, start, end, x_pix, y_pix.

BuildTrackingDataset.prepare_data(...): nessun clear-sky / neighboring.

dataset/tracking_dataset.py

MedicanesTrackDataset: ora solo pixel (x_pix, y_pix); se c’è label, tiene solo ==1.

