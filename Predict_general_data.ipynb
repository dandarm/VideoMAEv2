{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict general data\n",
    "\n",
    "TODO: fattorizzare con View_MED_val_preds e inference_classification, che probabilmente hanno già tutto, e unire o integrare il codice in più presente quì che non c'è negli altri due file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Impossibile caricare la libreria torch dynamo\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import csv\n",
    "import re\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./missing_data\")\n",
    "\n",
    "from dataset.datasets import MedicanesClsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "from timm.models import create_model\n",
    "\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "# from dataset.build_dataset import get_files_from_folder, extract_dates_pattern_airmass_rgb_20200101_0000\n",
    "# from dataset.build_dataset import load_cyclones_track_noheader, compute_pixel_scale, inside_tile, calc_tile_offsets, save_single_tile\n",
    "# from dataset.build_dataset import split_into_tiles_subfolders_and_track_dates, create_and_save_tile_from_complete_df\n",
    "# from dataset.build_dataset import create_final_df_csv\n",
    "# from dataset.build_dataset import get_gruppi_date, create_tile_videos, group_df_by_offsets\n",
    "# from medicane_utils.geo_const import latcorners, loncorners, x_center, y_center, create_basemap_obj\n",
    "# from medicane_utils.load_files import load_all_images\n",
    "\n",
    "from view_test_tiles import sub_select_frequency, expand_group, get_writer4animation, make_animation\n",
    "from model_analysis import create_df_predictions, video_pred_2_img_pred\n",
    "\n",
    "from arguments import prepare_finetuning_args, Args\n",
    "\n",
    "from dataset.data_manager import BuildDataset, DataManager\n",
    "\n",
    "\n",
    "file_master_df = \"all_data_all_methods_tracks_complete_fast.csv\"\n",
    "input_dir=\"../fromgcloud/2023\"\n",
    "output_dir = \"../airmassRGB/supervised/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non parto dal file di manos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413168\n",
      "1)  ->\n",
      "Creazione delle folder per i 168 video...\tSalvati 0 file - Erano già presenti 2688 file - File totali 2688\n",
      "168 video per il periodo (effettivo) da 2023-09-03 00:00:00 a 2023-09-03 18:35:00\n",
      "\n",
      "2)  ->\n",
      "Creazione delle folder per i 1728 video...\tSalvati 0 file - Erano già presenti 27648 file - File totali 27648\n",
      "1728 video per il periodo (effettivo) da 2023-09-03 23:25:00 a 2023-09-11 23:30:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = BuildDataset(type='SUPERVISED', master_df_path=file_master_df)\n",
    "data.load_master_df()\n",
    "\n",
    "# non applico il relabeling\n",
    "\n",
    "# filtro selezionando solo il 2023\n",
    "print(data.master_df.shape[0])\n",
    "df_2023 = data.master_df[data.master_df.datetime > datetime(2023,9,1)].copy()\n",
    "\n",
    "data.make_df_video(new_master_df=df_2023, output_dir=output_dir) #,  is_to_balance=True)\n",
    "\n",
    "csv_file = \"./general_inference_set.csv\"\n",
    "data.create_final_df_csv(output_dir, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2023.drop(columns=['lat','lon','x_pix','y_pix','name'], inplace=True)\n",
    "#df_2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  bonus -> mi guardo il video del periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2545"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#basemap_obj = create_basemap_obj()\n",
    "grouped = df_2023.groupby(\"path\", dropna=False)\n",
    "print(len(grouped))\n",
    "# CANCELLARE: usare create_med_video\n",
    "create_labeled_images_with_tiles(grouped, 'daniel_complete_tiles.gif', basemap_obj, 213, 196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset...\n",
      "DATASET length: 1896\n",
      "Creo il DistributedSampler con world_size 1 e rank 0\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fbf01e51fd0>\n",
      "Batch_size: 1\n"
     ]
    }
   ],
   "source": [
    "args = prepare_finetuning_args()\n",
    "args.test_path = csv_file\n",
    "\n",
    "test_m = DataManager(is_train=False, args=args, type_t='supervised', world_size=1, rank=0)\n",
    "test_m.create_classif_dataloader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del checkpoint da: ./output/checkpoint-best-CL10.pth\n",
      "Caricato state_dict con chiave: model\n",
      "Checkpoint caricato con successo!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv3d(3, 1408, kernel_size=(2, 14, 14), stride=(2, 14, 14))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0025641026441007853)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0051282052882015705)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.007692308165132999)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.010256410576403141)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.012820512987673283)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.015384616330265999)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.01794871874153614)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.020512821152806282)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.023076923564076424)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.025641025975346565)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.028205130249261856)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.030769232660531998)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03333333507180214)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03589743748307228)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03846153989434242)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.041025642305612564)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.043589744716882706)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04615384712815285)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04871794953942299)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05128205195069313)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05384615436196327)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05641026049852371)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.058974362909793854)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0615384615957737)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06410256773233414)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06666667014360428)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06923077255487442)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07179487496614456)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0743589773774147)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07692307978868484)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07948718219995499)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (32): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08205128461122513)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (33): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08461538702249527)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (34): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08717948943376541)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (35): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08974359184503555)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (36): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0923076942563057)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (37): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09487179666757584)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (38): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09743589907884598)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (39): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.10000000149011612)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (fc_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=1408, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carico il modello\n",
    "get_prediction = True\n",
    "args.test_mode = True\n",
    "args.init_ckpt = './output/checkpoint-best-CL10.pth'\n",
    "\n",
    "model = create_model(\n",
    "    args.model,\n",
    "    num_classes=args.nb_classes,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=args.drop_path,\n",
    "    #attn_drop_rate=0.0,\n",
    "    drop_block_rate=None,\n",
    "    **args.__dict__\n",
    ")\n",
    "\n",
    "model.to(args.device)\n",
    "model.eval()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ottengo il dataframe delle predizioni\n",
    "\n",
    "all_paths, all_preds, all_labels = get_path_pred_label(model, test_m.data_loader)\n",
    "df_predictions = create_df_predictions(all_paths, all_preds, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_w_predictions = data.df_video.merge(df_predictions, on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>tile_offset_x</th>\n",
       "      <th>tile_offset_y</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>orig_paths</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>03-09-2023_0115_0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-03 00:00:00</td>\n",
       "      <td>2023-09-03 01:15:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230903_0000.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>03-09-2023_0235_0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-03 01:20:00</td>\n",
       "      <td>2023-09-03 02:35:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230903_0120.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>03-09-2023_0355_0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-03 02:40:00</td>\n",
       "      <td>2023-09-03 03:55:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230903_0240.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>03-09-2023_0515_0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-03 04:00:00</td>\n",
       "      <td>2023-09-03 05:15:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230903_0400.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>03-09-2023_0635_0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-03 05:20:00</td>\n",
       "      <td>2023-09-03 06:35:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230903_0520.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1723</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "      <td>11-09-2023_1810_1065_196</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-11 16:55:00</td>\n",
       "      <td>2023-09-11 18:10:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230911_1655.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>1724</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "      <td>11-09-2023_1930_1065_196</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-11 18:15:00</td>\n",
       "      <td>2023-09-11 19:30:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230911_1815.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1725</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "      <td>11-09-2023_2050_1065_196</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-11 19:35:00</td>\n",
       "      <td>2023-09-11 20:50:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230911_1935.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1726</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "      <td>11-09-2023_2210_1065_196</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-11 20:55:00</td>\n",
       "      <td>2023-09-11 22:10:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230911_2055.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>1727</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "      <td>11-09-2023_2330_1065_196</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-11 22:15:00</td>\n",
       "      <td>2023-09-11 23:30:00</td>\n",
       "      <td>[../fromgcloud/airmass_rgb_20230911_2215.png, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1896 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  tile_offset_x  tile_offset_y                      path  label  \\\n",
       "0            0              0              0       03-09-2023_0115_0_0      0   \n",
       "1            1              0              0       03-09-2023_0235_0_0      0   \n",
       "2            2              0              0       03-09-2023_0355_0_0      0   \n",
       "3            3              0              0       03-09-2023_0515_0_0      0   \n",
       "4            4              0              0       03-09-2023_0635_0_0      0   \n",
       "...        ...            ...            ...                       ...    ...   \n",
       "1891      1723           1065            196  11-09-2023_1810_1065_196      0   \n",
       "1892      1724           1065            196  11-09-2023_1930_1065_196      0   \n",
       "1893      1725           1065            196  11-09-2023_2050_1065_196      0   \n",
       "1894      1726           1065            196  11-09-2023_2210_1065_196      0   \n",
       "1895      1727           1065            196  11-09-2023_2330_1065_196      0   \n",
       "\n",
       "              start_time            end_time  \\\n",
       "0    2023-09-03 00:00:00 2023-09-03 01:15:00   \n",
       "1    2023-09-03 01:20:00 2023-09-03 02:35:00   \n",
       "2    2023-09-03 02:40:00 2023-09-03 03:55:00   \n",
       "3    2023-09-03 04:00:00 2023-09-03 05:15:00   \n",
       "4    2023-09-03 05:20:00 2023-09-03 06:35:00   \n",
       "...                  ...                 ...   \n",
       "1891 2023-09-11 16:55:00 2023-09-11 18:10:00   \n",
       "1892 2023-09-11 18:15:00 2023-09-11 19:30:00   \n",
       "1893 2023-09-11 19:35:00 2023-09-11 20:50:00   \n",
       "1894 2023-09-11 20:55:00 2023-09-11 22:10:00   \n",
       "1895 2023-09-11 22:15:00 2023-09-11 23:30:00   \n",
       "\n",
       "                                             orig_paths  predictions  labels  \n",
       "0     [../fromgcloud/airmass_rgb_20230903_0000.png, ...            0       0  \n",
       "1     [../fromgcloud/airmass_rgb_20230903_0120.png, ...            0       0  \n",
       "2     [../fromgcloud/airmass_rgb_20230903_0240.png, ...            0       0  \n",
       "3     [../fromgcloud/airmass_rgb_20230903_0400.png, ...            0       0  \n",
       "4     [../fromgcloud/airmass_rgb_20230903_0520.png, ...            0       0  \n",
       "...                                                 ...          ...     ...  \n",
       "1891  [../fromgcloud/airmass_rgb_20230911_1655.png, ...            0       0  \n",
       "1892  [../fromgcloud/airmass_rgb_20230911_1815.png, ...            0       0  \n",
       "1893  [../fromgcloud/airmass_rgb_20230911_1935.png, ...            0       0  \n",
       "1894  [../fromgcloud/airmass_rgb_20230911_2055.png, ...            0       0  \n",
       "1895  [../fromgcloud/airmass_rgb_20230911_2215.png, ...            0       0  \n",
       "\n",
       "[1896 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_w_predictions#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = video_pred_2_img_pred(df_video_w_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>predictions</th>\n",
       "      <th>tmp_label</th>\n",
       "      <th>tile_offset_x</th>\n",
       "      <th>tile_offset_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230903_0000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230903_0005.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230903_0010.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230903_0015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230903_0020.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30331</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230911_2310.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30332</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230911_2315.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30333</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230911_2320.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30334</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230911_2325.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30335</th>\n",
       "      <td>../fromgcloud/airmass_rgb_20230911_2330.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1065</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path  predictions  tmp_label  \\\n",
       "0      ../fromgcloud/airmass_rgb_20230903_0000.png            0          0   \n",
       "1      ../fromgcloud/airmass_rgb_20230903_0005.png            0          0   \n",
       "2      ../fromgcloud/airmass_rgb_20230903_0010.png            0          0   \n",
       "3      ../fromgcloud/airmass_rgb_20230903_0015.png            0          0   \n",
       "4      ../fromgcloud/airmass_rgb_20230903_0020.png            0          0   \n",
       "...                                            ...          ...        ...   \n",
       "30331  ../fromgcloud/airmass_rgb_20230911_2310.png            0          0   \n",
       "30332  ../fromgcloud/airmass_rgb_20230911_2315.png            0          0   \n",
       "30333  ../fromgcloud/airmass_rgb_20230911_2320.png            0          0   \n",
       "30334  ../fromgcloud/airmass_rgb_20230911_2325.png            0          0   \n",
       "30335  ../fromgcloud/airmass_rgb_20230911_2330.png            0          0   \n",
       "\n",
       "       tile_offset_x  tile_offset_y  \n",
       "0                  0              0  \n",
       "1                  0              0  \n",
       "2                  0              0  \n",
       "3                  0              0  \n",
       "4                  0              0  \n",
       "...              ...            ...  \n",
       "30331           1065            196  \n",
       "30332           1065            196  \n",
       "30333           1065            196  \n",
       "30334           1065            196  \n",
       "30335           1065            196  \n",
       "\n",
       "[30336 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644\n"
     ]
    }
   ],
   "source": [
    "# se voglio limitare i frame da renderizzare\n",
    "\n",
    "df_2023_20m = sub_select_frequency(df_2023)\n",
    "print(df_2023_20m.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ottengo il dataframe di immagini per creare il video MED: \n",
    "df_data_merg = df_mapping.merge(df_2023_20m, on=['path', 'tile_offset_x', 'tile_offset_y'], how='left').drop(columns='label').rename(columns={'tmp_label':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#offsets = list(df_data_merg[['tile_offset_x','tile_offset_y']].value_counts().index.values)\n",
    "#offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_merg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from view_test_tiles import get_writer4animation, make_animation\n",
    "\n",
    "ffmpegwriter=get_writer4animation('./ffmpeg-7.0.2-amd64-static:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " abbiamo 2528 gruppi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.14 minuti\n",
      "Video salvato: daniel_prediction_1.mp4\n"
     ]
    }
   ],
   "source": [
    "make_animation(df_data_merg, nomefile='daniel_prediction_1.mp4', writer=ffmpegwriter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parto da folder di immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436 files loaded.\n",
      "[all] Intervallo immagini: 2023-02-24 00:00:00 -> 2023-02-28 23:55:00\n",
      "1)  ->\n",
      "Sbilanciato, ma comunque tengo traccia dei positivi e negativi\n",
      "Con cicloni: 30 \t ids: [0]\n",
      "Senza cicloni: 1386\n",
      "\n",
      "Creazione delle folder per i 1416 video...\t\n",
      "Salvati 0 file - Erano già presenti 22656 file - File totali 22656\n",
      "1416 video per il periodo (effettivo) da 2023-02-24 00:45:00 a 2023-02-28 23:00:00\n",
      "\n",
      "[all] CSV salvato in ./general_inference_set_all.csv con 1416 video\n"
     ]
    }
   ],
   "source": [
    "# Usa direttamente una folder di immagini (date nei nomi file)\n",
    "# Intervallo temporale dedotto dai file presenti\n",
    "\n",
    "manos_file = \"medicane_data_input/medicanes_new_windows.csv\"\n",
    "input_root = Path(input_dir)\n",
    "output_root = Path(output_dir)\n",
    "\n",
    "# Se True: ogni subfolder è un input separato (CSV separati)\n",
    "# Se False: tutte le subfolder vengono unite (CSV unico)\n",
    "split_by_subfolder = False\n",
    "\n",
    "def _ensure_trailing_slash(p):\n",
    "    s = str(p)\n",
    "    return s if s.endswith('/') else s + '/'\n",
    "\n",
    "def build_from_folder(input_dir_images, output_dir_images, name):\n",
    "    tracks_df = pd.read_csv(manos_file, parse_dates=['time', 'start_time', 'end_time'])\n",
    "\n",
    "    data = BuildDataset(type='SUPERVISED')\n",
    "    data.create_master_df(manos_file=manos_file, input_dir_images=input_dir_images, tracks_df=tracks_df)\n",
    "\n",
    "    start_dt = data.master_df['datetime'].min()\n",
    "    end_dt = data.master_df['datetime'].max()\n",
    "    print(f\"[{name}] Intervallo immagini: {start_dt} -> {end_dt}\")\n",
    "\n",
    "    output_dir_images = _ensure_trailing_slash(output_dir_images)\n",
    "    os.makedirs(output_dir_images, exist_ok=True)\n",
    "\n",
    "    # Usa le funzioni preesistenti per creare df_video e salvare le tile\n",
    "    data.make_df_video(output_dir=output_dir_images, is_to_balance=False)\n",
    "\n",
    "    suffix = (name or 'all').replace(' ', '_')\n",
    "    csv_file = f\"./general_inference_set_{suffix}.csv\"\n",
    "    data.create_final_df_csv(output_dir_images, csv_file)\n",
    "    print(f\"[{name}] CSV salvato in {csv_file} con {data.df_video.shape[0]} video\")\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'input_dir': input_dir_images,\n",
    "        'output_dir': output_dir_images,\n",
    "        'csv': csv_file,\n",
    "        'builder': data,\n",
    "    }\n",
    "\n",
    "# Lista dei dataset preparati\n",
    "\n",
    "datasets = []\n",
    "\n",
    "if split_by_subfolder:\n",
    "    subfolders = sorted([p for p in input_root.iterdir() if p.is_dir()])\n",
    "    if not subfolders:\n",
    "        datasets.append(build_from_folder(str(input_root), str(output_root), 'all'))\n",
    "    else:\n",
    "        for sub in subfolders:\n",
    "            out_dir = output_root / sub.name\n",
    "            datasets.append(build_from_folder(str(sub), str(out_dir), sub.name))\n",
    "else:\n",
    "    # merge: include anche eventuali subfolder (rglob)\n",
    "    datasets.append(build_from_folder(str(input_root), str(output_root), 'all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del checkpoint da: ./output/checkpoint-best-lr-again2.pth\n",
      "Caricato state_dict con chiave: model\n",
      "Testa del modello rimossa dal checkpoint per evitare mismatch di numero di classi col preaddestrato.\n",
      "Checkpoint caricato con successo!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv3d(3, 1408, kernel_size=(2, 14, 14), stride=(2, 14, 14))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0025641026441007853)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0051282052882015705)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.007692308165132999)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.010256410576403141)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.012820512987673283)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.015384616330265999)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.01794871874153614)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.020512821152806282)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.023076923564076424)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.025641025975346565)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.028205130249261856)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.030769232660531998)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03333333507180214)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03589743748307228)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.03846153989434242)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.041025642305612564)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.043589744716882706)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04615384712815285)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04871794953942299)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05128205195069313)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05384615436196327)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05641026049852371)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.058974362909793854)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0615384615957737)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06410256773233414)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06666667014360428)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06923077255487442)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07179487496614456)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0743589773774147)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07692307978868484)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.07948718219995499)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (32): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08205128461122513)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (33): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08461538702249527)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (34): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08717948943376541)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (35): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08974359184503555)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (36): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0923076942563057)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (37): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09487179666757584)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (38): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09743589907884598)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (39): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.10000000149011612)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (fc_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=1408, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = prepare_finetuning_args()\n",
    "\n",
    "# carico il modello\n",
    "get_prediction = True\n",
    "args.test_mode = True\n",
    "args.init_ckpt = './output/checkpoint-best-lr-again2.pth'\n",
    "\n",
    "model = create_model(\n",
    "    args.model,\n",
    "    num_classes=args.nb_classes,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=args.drop_path,\n",
    "    #attn_drop_rate=0.0,\n",
    "    drop_block_rate=None,\n",
    "    **args.__dict__\n",
    ")\n",
    "\n",
    "model.to(args.device)\n",
    "model.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all] inferenza su ./general_inference_set_all.csv\n",
      "Getting dataset...\n",
      "DATASET length: 1416\n",
      "Creo il DistributedSampler con world_size 1 e rank 0\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fab5c494310>\n",
      "Batch_size local: 1\n",
      "Val:  [   0/1416]  eta: 22:48:04  loss: 0.6940 (0.6940)  acc: 0.0000 (0.0000)  bal_acc: 0.0000 (0.0000)  pod: 0.0000 (0.0000)  far: 1.0000 (1.0000)  time: 57.9691 (57.9691 -- 57.9691)  data: 1.7571 (1.7571 -- 1.7571)  max mem: 4528\n",
      "Val:  [  10/1416]  eta: 2:11:40  loss: 0.6939 (0.6935)  acc: 0.0000 (0.1818)  bal_acc: 0.0000 (0.0909)  pod: 0.0000 (0.0000)  far: 1.0000 (0.8182)  time: 5.6188 (0.3808 -- 57.9691)  data: 0.1599 (0.0001 -- 1.7571)  max mem: 4528\n",
      "Val:  [  20/1416]  eta: 1:12:42  loss: 0.6935 (0.6933)  acc: 0.0000 (0.3810)  bal_acc: 0.0000 (0.1905)  pod: 0.0000 (0.0000)  far: 1.0000 (0.6190)  time: 0.3830 (0.3808 -- 0.3862)  data: 0.0002 (0.0001 -- 0.0011)  max mem: 4528\n",
      "Val:  [  30/1416]  eta: 0:51:45  loss: 0.6939 (0.6935)  acc: 0.0000 (0.2581)  bal_acc: 0.0000 (0.1290)  pod: 0.0000 (0.0000)  far: 1.0000 (0.7419)  time: 0.3824 (0.3812 -- 0.3842)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [  40/1416]  eta: 0:40:59  loss: 0.6940 (0.6936)  acc: 0.0000 (0.1951)  bal_acc: 0.0000 (0.0976)  pod: 0.0000 (0.0000)  far: 1.0000 (0.8049)  time: 0.3830 (0.3820 -- 0.3847)  data: 0.0002 (0.0001 -- 0.0005)  max mem: 4528\n",
      "Val:  [  50/1416]  eta: 0:34:25  loss: 0.6941 (0.6937)  acc: 0.0000 (0.1569)  bal_acc: 0.0000 (0.0784)  pod: 0.0000 (0.0000)  far: 1.0000 (0.8431)  time: 0.3839 (0.3823 -- 0.3852)  data: 0.0002 (0.0001 -- 0.0014)  max mem: 4528\n",
      "Val:  [  60/1416]  eta: 0:30:00  loss: 0.6941 (0.6935)  acc: 0.0000 (0.2623)  bal_acc: 0.0000 (0.1311)  pod: 0.0000 (0.0000)  far: 1.0000 (0.7377)  time: 0.3845 (0.3836 -- 0.3852)  data: 0.0002 (0.0001 -- 0.0014)  max mem: 4528\n",
      "Val:  [  70/1416]  eta: 0:26:48  loss: 0.6920 (0.6933)  acc: 1.0000 (0.3662)  bal_acc: 0.5000 (0.1831)  pod: 0.0000 (0.0000)  far: 0.0000 (0.6338)  time: 0.3848 (0.3840 -- 0.3852)  data: 0.0002 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [  80/1416]  eta: 0:24:22  loss: 0.6921 (0.6932)  acc: 1.0000 (0.4444)  bal_acc: 0.5000 (0.2222)  pod: 0.0000 (0.0000)  far: 0.0000 (0.5556)  time: 0.3852 (0.3844 -- 0.3862)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [  90/1416]  eta: 0:22:28  loss: 0.6921 (0.6930)  acc: 1.0000 (0.5055)  bal_acc: 0.5000 (0.2527)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4945)  time: 0.3859 (0.3844 -- 0.3868)  data: 0.0002 (0.0001 -- 0.0008)  max mem: 4528\n",
      "Val:  [ 100/1416]  eta: 0:20:56  loss: 0.6921 (0.6930)  acc: 1.0000 (0.5545)  bal_acc: 0.5000 (0.2772)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4455)  time: 0.3868 (0.3856 -- 0.3880)  data: 0.0002 (0.0001 -- 0.0008)  max mem: 4528\n",
      "Val:  [ 110/1416]  eta: 0:19:40  loss: 0.6921 (0.6929)  acc: 1.0000 (0.5946)  bal_acc: 0.5000 (0.2973)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4054)  time: 0.3874 (0.3866 -- 0.3890)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 120/1416]  eta: 0:18:35  loss: 0.6921 (0.6929)  acc: 1.0000 (0.6033)  bal_acc: 0.5000 (0.3017)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3967)  time: 0.3881 (0.3866 -- 0.3925)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 130/1416]  eta: 0:17:40  loss: 0.6940 (0.6929)  acc: 0.0000 (0.5573)  bal_acc: 0.0000 (0.2786)  pod: 0.0000 (0.0000)  far: 1.0000 (0.4427)  time: 0.3890 (0.3874 -- 0.3925)  data: 0.0002 (0.0001 -- 0.0010)  max mem: 4528\n",
      "Val:  [ 140/1416]  eta: 0:16:53  loss: 0.6940 (0.6930)  acc: 0.0000 (0.5390)  bal_acc: 0.0000 (0.2695)  pod: 0.0000 (0.0000)  far: 1.0000 (0.4610)  time: 0.3894 (0.3886 -- 0.3907)  data: 0.0002 (0.0001 -- 0.0010)  max mem: 4528\n",
      "Val:  [ 150/1416]  eta: 0:16:11  loss: 0.6925 (0.6929)  acc: 1.0000 (0.5695)  bal_acc: 0.5000 (0.2848)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4305)  time: 0.3897 (0.3886 -- 0.3915)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 160/1416]  eta: 0:15:34  loss: 0.6924 (0.6929)  acc: 1.0000 (0.5714)  bal_acc: 0.5000 (0.2857)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4286)  time: 0.3901 (0.3886 -- 0.3918)  data: 0.0002 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 170/1416]  eta: 0:15:01  loss: 0.6942 (0.6930)  acc: 0.0000 (0.5380)  bal_acc: 0.0000 (0.2690)  pod: 0.0000 (0.0000)  far: 1.0000 (0.4620)  time: 0.3907 (0.3890 -- 0.3923)  data: 0.0002 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 180/1416]  eta: 0:14:31  loss: 0.6940 (0.6930)  acc: 0.0000 (0.5359)  bal_acc: 0.0000 (0.2680)  pod: 0.0000 (0.0000)  far: 1.0000 (0.4641)  time: 0.3910 (0.3895 -- 0.3923)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 190/1416]  eta: 0:14:04  loss: 0.6923 (0.6930)  acc: 1.0000 (0.5602)  bal_acc: 0.5000 (0.2801)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4398)  time: 0.3910 (0.3897 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 200/1416]  eta: 0:13:39  loss: 0.6922 (0.6929)  acc: 1.0000 (0.5821)  bal_acc: 0.5000 (0.2910)  pod: 0.0000 (0.0000)  far: 0.0000 (0.4179)  time: 0.3909 (0.3899 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 210/1416]  eta: 0:13:16  loss: 0.6922 (0.6929)  acc: 1.0000 (0.6019)  bal_acc: 0.5000 (0.3009)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3981)  time: 0.3909 (0.3900 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 220/1416]  eta: 0:12:55  loss: 0.6922 (0.6929)  acc: 1.0000 (0.6154)  bal_acc: 0.5000 (0.3077)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3846)  time: 0.3914 (0.3902 -- 0.3926)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 230/1416]  eta: 0:12:35  loss: 0.6922 (0.6929)  acc: 1.0000 (0.6277)  bal_acc: 0.5000 (0.3139)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3723)  time: 0.3918 (0.3905 -- 0.3926)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 240/1416]  eta: 0:12:17  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6432)  bal_acc: 0.5000 (0.3216)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3568)  time: 0.3920 (0.3916 -- 0.3925)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 250/1416]  eta: 0:12:00  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6574)  bal_acc: 0.5000 (0.3287)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3426)  time: 0.3923 (0.3916 -- 0.3953)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 260/1416]  eta: 0:11:43  loss: 0.6921 (0.6928)  acc: 1.0000 (0.6705)  bal_acc: 0.5000 (0.3352)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3295)  time: 0.3925 (0.3916 -- 0.3953)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 270/1416]  eta: 0:11:28  loss: 0.6920 (0.6928)  acc: 1.0000 (0.6827)  bal_acc: 0.5000 (0.3413)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3173)  time: 0.3925 (0.3918 -- 0.3941)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 280/1416]  eta: 0:11:14  loss: 0.6920 (0.6927)  acc: 1.0000 (0.6868)  bal_acc: 0.5000 (0.3434)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3132)  time: 0.3925 (0.3914 -- 0.3941)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 290/1416]  eta: 0:11:00  loss: 0.6939 (0.6928)  acc: 0.0000 (0.6632)  bal_acc: 0.0000 (0.3316)  pod: 0.0000 (0.0000)  far: 1.0000 (0.3368)  time: 0.3924 (0.3905 -- 0.3946)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 300/1416]  eta: 0:10:47  loss: 0.6939 (0.6928)  acc: 0.0000 (0.6711)  bal_acc: 0.0000 (0.3355)  pod: 0.0000 (0.0000)  far: 1.0000 (0.3289)  time: 0.3926 (0.3905 -- 0.3948)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 310/1416]  eta: 0:10:34  loss: 0.6923 (0.6928)  acc: 1.0000 (0.6817)  bal_acc: 0.5000 (0.3408)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3183)  time: 0.3925 (0.3906 -- 0.3948)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 320/1416]  eta: 0:10:23  loss: 0.6924 (0.6928)  acc: 1.0000 (0.6916)  bal_acc: 0.5000 (0.3458)  pod: 0.0000 (0.0000)  far: 0.0000 (0.3084)  time: 0.3921 (0.3906 -- 0.3946)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 330/1416]  eta: 0:10:11  loss: 0.6926 (0.6928)  acc: 1.0000 (0.6949)  bal_acc: 0.5000 (0.3474)  pod: 0.0000 (0.0181)  far: 0.0000 (0.3051)  time: 0.3922 (0.3911 -- 0.3951)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 340/1416]  eta: 0:10:00  loss: 0.6926 (0.6927)  acc: 1.0000 (0.7038)  bal_acc: 0.5000 (0.3519)  pod: 1.0000 (0.0469)  far: 0.0000 (0.2962)  time: 0.3923 (0.3911 -- 0.3951)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 350/1416]  eta: 0:09:49  loss: 0.6924 (0.6927)  acc: 1.0000 (0.7094)  bal_acc: 0.5000 (0.3547)  pod: 1.0000 (0.0712)  far: 0.0000 (0.2877)  time: 0.3923 (0.3915 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [ 360/1416]  eta: 0:09:39  loss: 0.6926 (0.6928)  acc: 1.0000 (0.6981)  bal_acc: 0.5000 (0.3490)  pod: 0.0000 (0.0693)  far: 0.0000 (0.2992)  time: 0.3923 (0.3915 -- 0.3935)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 370/1416]  eta: 0:09:29  loss: 0.6926 (0.6928)  acc: 0.0000 (0.6981)  bal_acc: 0.0000 (0.3491)  pod: 0.0000 (0.0674)  far: 0.0000 (0.2992)  time: 0.3924 (0.3915 -- 0.3938)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 380/1416]  eta: 0:09:20  loss: 0.6920 (0.6928)  acc: 1.0000 (0.6982)  bal_acc: 0.5000 (0.3491)  pod: 0.0000 (0.0656)  far: 0.0000 (0.2992)  time: 0.3923 (0.3915 -- 0.3938)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 390/1416]  eta: 0:09:10  loss: 0.6921 (0.6928)  acc: 1.0000 (0.6957)  bal_acc: 0.5000 (0.3478)  pod: 0.0000 (0.0639)  far: 0.0000 (0.3018)  time: 0.3921 (0.3912 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 400/1416]  eta: 0:09:01  loss: 0.6923 (0.6928)  acc: 1.0000 (0.6933)  bal_acc: 0.5000 (0.3466)  pod: 0.0000 (0.0623)  far: 0.0000 (0.3042)  time: 0.3920 (0.3912 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 410/1416]  eta: 0:08:53  loss: 0.6939 (0.6928)  acc: 0.0000 (0.6813)  bal_acc: 0.0000 (0.3406)  pod: 0.0000 (0.0608)  far: 1.0000 (0.3163)  time: 0.3921 (0.3909 -- 0.3930)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 420/1416]  eta: 0:08:44  loss: 0.6938 (0.6928)  acc: 0.0000 (0.6793)  bal_acc: 0.0000 (0.3397)  pod: 0.0000 (0.0594)  far: 1.0000 (0.3183)  time: 0.3921 (0.3907 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 430/1416]  eta: 0:08:36  loss: 0.6923 (0.6928)  acc: 1.0000 (0.6845)  bal_acc: 0.5000 (0.3422)  pod: 0.0000 (0.0580)  far: 0.0000 (0.3132)  time: 0.3918 (0.3907 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 440/1416]  eta: 0:08:27  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6916)  bal_acc: 0.5000 (0.3458)  pod: 0.0000 (0.0567)  far: 0.0000 (0.3061)  time: 0.3917 (0.3903 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 450/1416]  eta: 0:08:20  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6984)  bal_acc: 0.5000 (0.3492)  pod: 0.0000 (0.0554)  far: 0.0000 (0.2993)  time: 0.3915 (0.3903 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 460/1416]  eta: 0:08:12  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7050)  bal_acc: 0.5000 (0.3525)  pod: 0.0000 (0.0542)  far: 0.0000 (0.2928)  time: 0.3914 (0.3904 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 470/1416]  eta: 0:08:04  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7113)  bal_acc: 0.5000 (0.3556)  pod: 0.0000 (0.0531)  far: 0.0000 (0.2866)  time: 0.3916 (0.3904 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 480/1416]  eta: 0:07:57  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7173)  bal_acc: 0.5000 (0.3586)  pod: 0.0000 (0.0520)  far: 0.0000 (0.2807)  time: 0.3916 (0.3905 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 490/1416]  eta: 0:07:49  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7230)  bal_acc: 0.5000 (0.3615)  pod: 0.0000 (0.0509)  far: 0.0000 (0.2749)  time: 0.3917 (0.3905 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 500/1416]  eta: 0:07:42  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7285)  bal_acc: 0.5000 (0.3643)  pod: 0.0000 (0.0499)  far: 0.0000 (0.2695)  time: 0.3917 (0.3898 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 510/1416]  eta: 0:07:35  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7339)  bal_acc: 0.5000 (0.3669)  pod: 0.0000 (0.0489)  far: 0.0000 (0.2642)  time: 0.3911 (0.3894 -- 0.3930)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 520/1416]  eta: 0:07:28  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7390)  bal_acc: 0.5000 (0.3695)  pod: 0.0000 (0.0480)  far: 0.0000 (0.2591)  time: 0.3910 (0.3894 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 530/1416]  eta: 0:07:21  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7345)  bal_acc: 0.5000 (0.3672)  pod: 0.0000 (0.0471)  far: 0.0000 (0.2637)  time: 0.3915 (0.3900 -- 0.3936)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 540/1416]  eta: 0:07:15  loss: 0.6941 (0.6927)  acc: 0.0000 (0.7209)  bal_acc: 0.0000 (0.3604)  pod: 0.0000 (0.0462)  far: 1.0000 (0.2773)  time: 0.3916 (0.3904 -- 0.3936)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 550/1416]  eta: 0:07:08  loss: 0.6941 (0.6927)  acc: 0.0000 (0.7078)  bal_acc: 0.0000 (0.3539)  pod: 0.0000 (0.0454)  far: 1.0000 (0.2904)  time: 0.3914 (0.3903 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 560/1416]  eta: 0:07:01  loss: 0.6941 (0.6927)  acc: 0.0000 (0.7023)  bal_acc: 0.0000 (0.3512)  pod: 0.0000 (0.0446)  far: 1.0000 (0.2959)  time: 0.3914 (0.3897 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 570/1416]  eta: 0:06:55  loss: 0.6937 (0.6928)  acc: 0.0000 (0.6935)  bal_acc: 0.0000 (0.3468)  pod: 0.0000 (0.0438)  far: 1.0000 (0.3047)  time: 0.3913 (0.3897 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 580/1416]  eta: 0:06:49  loss: 0.6941 (0.6928)  acc: 0.0000 (0.6816)  bal_acc: 0.0000 (0.3408)  pod: 0.0000 (0.0430)  far: 1.0000 (0.3167)  time: 0.3912 (0.3902 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 590/1416]  eta: 0:06:42  loss: 0.6941 (0.6928)  acc: 0.0000 (0.6785)  bal_acc: 0.0000 (0.3393)  pod: 0.0000 (0.0491)  far: 1.0000 (0.3198)  time: 0.3911 (0.3902 -- 0.3919)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 600/1416]  eta: 0:06:36  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6839)  bal_acc: 0.5000 (0.3419)  pod: 0.0000 (0.0483)  far: 0.0000 (0.3145)  time: 0.3909 (0.3901 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 610/1416]  eta: 0:06:30  loss: 0.6922 (0.6928)  acc: 1.0000 (0.6890)  bal_acc: 0.5000 (0.3445)  pod: 0.0000 (0.0475)  far: 0.0000 (0.3093)  time: 0.3909 (0.3901 -- 0.3916)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 620/1416]  eta: 0:06:24  loss: 0.6921 (0.6928)  acc: 1.0000 (0.6940)  bal_acc: 0.5000 (0.3470)  pod: 0.0000 (0.0467)  far: 0.0000 (0.3043)  time: 0.3909 (0.3897 -- 0.3919)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 630/1416]  eta: 0:06:18  loss: 0.6921 (0.6928)  acc: 1.0000 (0.6989)  bal_acc: 0.5000 (0.3494)  pod: 0.0000 (0.0460)  far: 0.0000 (0.2995)  time: 0.3908 (0.3892 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 640/1416]  eta: 0:06:12  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7036)  bal_acc: 0.5000 (0.3518)  pod: 0.0000 (0.0452)  far: 0.0000 (0.2949)  time: 0.3907 (0.3892 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 650/1416]  eta: 0:06:06  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7051)  bal_acc: 0.5000 (0.3525)  pod: 0.0000 (0.0445)  far: 0.0000 (0.2934)  time: 0.3908 (0.3892 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 660/1416]  eta: 0:06:00  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7020)  bal_acc: 0.5000 (0.3510)  pod: 0.0000 (0.0439)  far: 0.0000 (0.2965)  time: 0.3910 (0.3892 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 670/1416]  eta: 0:05:55  loss: 0.6939 (0.6928)  acc: 0.0000 (0.6975)  bal_acc: 0.0000 (0.3487)  pod: 0.0000 (0.0432)  far: 1.0000 (0.3010)  time: 0.3908 (0.3893 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 680/1416]  eta: 0:05:49  loss: 0.6926 (0.6928)  acc: 1.0000 (0.6975)  bal_acc: 0.5000 (0.3488)  pod: 0.0000 (0.0426)  far: 0.0000 (0.3010)  time: 0.3906 (0.3893 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 690/1416]  eta: 0:05:43  loss: 0.6922 (0.6928)  acc: 1.0000 (0.7004)  bal_acc: 0.5000 (0.3502)  pod: 0.0000 (0.0420)  far: 0.0000 (0.2981)  time: 0.3906 (0.3894 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 700/1416]  eta: 0:05:38  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7047)  bal_acc: 0.5000 (0.3524)  pod: 0.0000 (0.0414)  far: 0.0000 (0.2939)  time: 0.3904 (0.3893 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 710/1416]  eta: 0:05:32  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7089)  bal_acc: 0.5000 (0.3544)  pod: 0.0000 (0.0408)  far: 0.0000 (0.2897)  time: 0.3903 (0.3893 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 720/1416]  eta: 0:05:27  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7129)  bal_acc: 0.5000 (0.3564)  pod: 0.0000 (0.0402)  far: 0.0000 (0.2857)  time: 0.3903 (0.3893 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [ 730/1416]  eta: 0:05:21  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7168)  bal_acc: 0.5000 (0.3584)  pod: 0.0000 (0.0397)  far: 0.0000 (0.2818)  time: 0.3902 (0.3890 -- 0.3916)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 740/1416]  eta: 0:05:16  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7206)  bal_acc: 0.5000 (0.3603)  pod: 0.0000 (0.0391)  far: 0.0000 (0.2780)  time: 0.3904 (0.3890 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 750/1416]  eta: 0:05:11  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7244)  bal_acc: 0.5000 (0.3622)  pod: 0.0000 (0.0386)  far: 0.0000 (0.2743)  time: 0.3902 (0.3887 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 760/1416]  eta: 0:05:05  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7280)  bal_acc: 0.5000 (0.3640)  pod: 0.0000 (0.0381)  far: 0.0000 (0.2707)  time: 0.3900 (0.3887 -- 0.3917)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 770/1416]  eta: 0:05:00  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7315)  bal_acc: 0.5000 (0.3658)  pod: 0.0000 (0.0376)  far: 0.0000 (0.2672)  time: 0.3904 (0.3890 -- 0.3917)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 780/1416]  eta: 0:04:55  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7337)  bal_acc: 0.5000 (0.3668)  pod: 0.0000 (0.0371)  far: 0.0000 (0.2650)  time: 0.3907 (0.3895 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 790/1416]  eta: 0:04:49  loss: 0.6939 (0.6927)  acc: 0.0000 (0.7244)  bal_acc: 0.0000 (0.3622)  pod: 0.0000 (0.0367)  far: 1.0000 (0.2743)  time: 0.3907 (0.3894 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 800/1416]  eta: 0:04:44  loss: 0.6941 (0.6927)  acc: 0.0000 (0.7154)  bal_acc: 0.0000 (0.3577)  pod: 0.0000 (0.0362)  far: 1.0000 (0.2834)  time: 0.3906 (0.3894 -- 0.3917)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 810/1416]  eta: 0:04:39  loss: 0.6941 (0.6927)  acc: 0.0000 (0.7065)  bal_acc: 0.0000 (0.3533)  pod: 0.0000 (0.0358)  far: 1.0000 (0.2922)  time: 0.3906 (0.3896 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 820/1416]  eta: 0:04:34  loss: 0.6941 (0.6927)  acc: 0.0000 (0.6991)  bal_acc: 0.0000 (0.3496)  pod: 0.0000 (0.0353)  far: 1.0000 (0.2996)  time: 0.3908 (0.3896 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 830/1416]  eta: 0:04:29  loss: 0.6939 (0.6928)  acc: 0.0000 (0.6968)  bal_acc: 0.0000 (0.3484)  pod: 0.0000 (0.0349)  far: 1.0000 (0.3020)  time: 0.3906 (0.3891 -- 0.3919)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 840/1416]  eta: 0:04:24  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7004)  bal_acc: 0.5000 (0.3502)  pod: 0.0000 (0.0345)  far: 0.0000 (0.2985)  time: 0.3901 (0.3888 -- 0.3918)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 850/1416]  eta: 0:04:19  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7039)  bal_acc: 0.5000 (0.3519)  pod: 0.0000 (0.0341)  far: 0.0000 (0.2949)  time: 0.3899 (0.3888 -- 0.3915)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 860/1416]  eta: 0:04:14  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7073)  bal_acc: 0.5000 (0.3537)  pod: 0.0000 (0.0337)  far: 0.0000 (0.2915)  time: 0.3902 (0.3893 -- 0.3914)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 870/1416]  eta: 0:04:09  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7107)  bal_acc: 0.5000 (0.3553)  pod: 0.0000 (0.0333)  far: 0.0000 (0.2882)  time: 0.3906 (0.3892 -- 0.3916)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 880/1416]  eta: 0:04:04  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7140)  bal_acc: 0.5000 (0.3570)  pod: 0.0000 (0.0329)  far: 0.0000 (0.2849)  time: 0.3907 (0.3892 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 890/1416]  eta: 0:03:59  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7172)  bal_acc: 0.5000 (0.3586)  pod: 0.0000 (0.0325)  far: 0.0000 (0.2817)  time: 0.3909 (0.3894 -- 0.3921)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 900/1416]  eta: 0:03:54  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7203)  bal_acc: 0.5000 (0.3602)  pod: 0.0000 (0.0322)  far: 0.0000 (0.2786)  time: 0.3910 (0.3898 -- 0.3920)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 910/1416]  eta: 0:03:49  loss: 0.6923 (0.6927)  acc: 1.0000 (0.7212)  bal_acc: 0.5000 (0.3606)  pod: 0.0000 (0.0318)  far: 0.0000 (0.2777)  time: 0.3908 (0.3898 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 920/1416]  eta: 0:03:44  loss: 0.6927 (0.6927)  acc: 1.0000 (0.7166)  bal_acc: 0.5000 (0.3583)  pod: 0.0000 (0.0315)  far: 0.0000 (0.2823)  time: 0.3912 (0.3898 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 930/1416]  eta: 0:03:39  loss: 0.6940 (0.6927)  acc: 0.0000 (0.7089)  bal_acc: 0.0000 (0.3545)  pod: 0.0000 (0.0311)  far: 1.0000 (0.2900)  time: 0.3913 (0.3898 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 940/1416]  eta: 0:03:34  loss: 0.6922 (0.6927)  acc: 0.0000 (0.7120)  bal_acc: 0.0000 (0.3560)  pod: 0.0000 (0.0308)  far: 0.0000 (0.2869)  time: 0.3909 (0.3897 -- 0.3924)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [ 950/1416]  eta: 0:03:30  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7150)  bal_acc: 0.5000 (0.3575)  pod: 0.0000 (0.0305)  far: 0.0000 (0.2839)  time: 0.3907 (0.3895 -- 0.3926)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 960/1416]  eta: 0:03:25  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7180)  bal_acc: 0.5000 (0.3590)  pod: 0.0000 (0.0302)  far: 0.0000 (0.2810)  time: 0.3911 (0.3895 -- 0.3926)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 970/1416]  eta: 0:03:20  loss: 0.6922 (0.6927)  acc: 1.0000 (0.7209)  bal_acc: 0.5000 (0.3605)  pod: 0.0000 (0.0299)  far: 0.0000 (0.2781)  time: 0.3911 (0.3902 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 980/1416]  eta: 0:03:15  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7238)  bal_acc: 0.5000 (0.3619)  pod: 0.0000 (0.0296)  far: 0.0000 (0.2752)  time: 0.3911 (0.3898 -- 0.3923)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [ 990/1416]  eta: 0:03:11  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7265)  bal_acc: 0.5000 (0.3633)  pod: 0.0000 (0.0293)  far: 0.0000 (0.2725)  time: 0.3914 (0.3898 -- 0.3923)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1000/1416]  eta: 0:03:06  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7293)  bal_acc: 0.5000 (0.3646)  pod: 0.0000 (0.0290)  far: 0.0000 (0.2697)  time: 0.3913 (0.3900 -- 0.3923)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1010/1416]  eta: 0:03:01  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7319)  bal_acc: 0.5000 (0.3660)  pod: 0.0000 (0.0287)  far: 0.0000 (0.2671)  time: 0.3913 (0.3900 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1020/1416]  eta: 0:02:56  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7346)  bal_acc: 0.5000 (0.3673)  pod: 0.0000 (0.0284)  far: 0.0000 (0.2644)  time: 0.3917 (0.3909 -- 0.3923)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1030/1416]  eta: 0:02:52  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7352)  bal_acc: 0.5000 (0.3676)  pod: 0.0000 (0.0281)  far: 0.0000 (0.2638)  time: 0.3918 (0.3912 -- 0.3925)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1040/1416]  eta: 0:02:47  loss: 0.6921 (0.6927)  acc: 1.0000 (0.7378)  bal_acc: 0.5000 (0.3689)  pod: 0.0000 (0.0279)  far: 0.0000 (0.2613)  time: 0.3919 (0.3912 -- 0.3925)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1050/1416]  eta: 0:02:42  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7402)  bal_acc: 0.5000 (0.3701)  pod: 0.0000 (0.0276)  far: 0.0000 (0.2588)  time: 0.3919 (0.3910 -- 0.3927)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1060/1416]  eta: 0:02:38  loss: 0.6920 (0.6927)  acc: 1.0000 (0.7427)  bal_acc: 0.5000 (0.3713)  pod: 0.0000 (0.0273)  far: 0.0000 (0.2564)  time: 0.3921 (0.3909 -- 0.3934)  data: 0.0002 (0.0001 -- 0.0005)  max mem: 4528\n",
      "Val:  [1070/1416]  eta: 0:02:33  loss: 0.6920 (0.6926)  acc: 1.0000 (0.7451)  bal_acc: 0.5000 (0.3725)  pod: 0.0000 (0.0271)  far: 0.0000 (0.2540)  time: 0.3918 (0.3901 -- 0.3934)  data: 0.0001 (0.0001 -- 0.0005)  max mem: 4528\n",
      "Val:  [1080/1416]  eta: 0:02:29  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7475)  bal_acc: 0.5000 (0.3737)  pod: 0.0000 (0.0268)  far: 0.0000 (0.2516)  time: 0.3915 (0.3901 -- 0.3930)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1090/1416]  eta: 0:02:24  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7498)  bal_acc: 0.5000 (0.3749)  pod: 0.0000 (0.0266)  far: 0.0000 (0.2493)  time: 0.3916 (0.3909 -- 0.3922)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1100/1416]  eta: 0:02:19  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7520)  bal_acc: 0.5000 (0.3760)  pod: 0.0000 (0.0263)  far: 0.0000 (0.2470)  time: 0.3917 (0.3910 -- 0.3930)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1110/1416]  eta: 0:02:15  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7543)  bal_acc: 0.5000 (0.3771)  pod: 0.0000 (0.0261)  far: 0.0000 (0.2448)  time: 0.3920 (0.3910 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1120/1416]  eta: 0:02:10  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7565)  bal_acc: 0.5000 (0.3782)  pod: 0.0000 (0.0259)  far: 0.0000 (0.2426)  time: 0.3922 (0.3915 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1130/1416]  eta: 0:02:06  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7586)  bal_acc: 0.5000 (0.3793)  pod: 0.0000 (0.0256)  far: 0.0000 (0.2405)  time: 0.3924 (0.3915 -- 0.3934)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1140/1416]  eta: 0:02:01  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7607)  bal_acc: 0.5000 (0.3804)  pod: 0.0000 (0.0254)  far: 0.0000 (0.2384)  time: 0.3927 (0.3922 -- 0.3934)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1150/1416]  eta: 0:01:57  loss: 0.6923 (0.6926)  acc: 1.0000 (0.7611)  bal_acc: 0.5000 (0.3805)  pod: 0.0000 (0.0252)  far: 0.0000 (0.2381)  time: 0.3928 (0.3919 -- 0.3942)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1160/1416]  eta: 0:01:52  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7631)  bal_acc: 0.5000 (0.3816)  pod: 0.0000 (0.0250)  far: 0.0000 (0.2360)  time: 0.3928 (0.3913 -- 0.3942)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1170/1416]  eta: 0:01:48  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7626)  bal_acc: 0.5000 (0.3813)  pod: 0.0000 (0.0248)  far: 0.0000 (0.2365)  time: 0.3928 (0.3913 -- 0.3941)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1180/1416]  eta: 0:01:43  loss: 0.6939 (0.6926)  acc: 0.0000 (0.7570)  bal_acc: 0.0000 (0.3785)  pod: 0.0000 (0.0246)  far: 1.0000 (0.2422)  time: 0.3929 (0.3919 -- 0.3946)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1190/1416]  eta: 0:01:39  loss: 0.6923 (0.6926)  acc: 1.0000 (0.7590)  bal_acc: 0.5000 (0.3795)  pod: 0.0000 (0.0243)  far: 0.0000 (0.2401)  time: 0.3929 (0.3917 -- 0.3946)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1200/1416]  eta: 0:01:34  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7610)  bal_acc: 0.5000 (0.3805)  pod: 0.0000 (0.0241)  far: 0.0000 (0.2381)  time: 0.3928 (0.3917 -- 0.3942)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1210/1416]  eta: 0:01:30  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7630)  bal_acc: 0.5000 (0.3815)  pod: 0.0000 (0.0239)  far: 0.0000 (0.2362)  time: 0.3930 (0.3917 -- 0.3946)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [1220/1416]  eta: 0:01:25  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7649)  bal_acc: 0.5000 (0.3825)  pod: 0.0000 (0.0238)  far: 0.0000 (0.2342)  time: 0.3932 (0.3919 -- 0.3946)  data: 0.0002 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [1230/1416]  eta: 0:01:21  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7669)  bal_acc: 0.5000 (0.3834)  pod: 0.0000 (0.0236)  far: 0.0000 (0.2323)  time: 0.3933 (0.3919 -- 0.3949)  data: 0.0002 (0.0001 -- 0.0004)  max mem: 4528\n",
      "Val:  [1240/1416]  eta: 0:01:16  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7687)  bal_acc: 0.5000 (0.3844)  pod: 0.0000 (0.0234)  far: 0.0000 (0.2305)  time: 0.3932 (0.3919 -- 0.3949)  data: 0.0002 (0.0001 -- 0.0006)  max mem: 4528\n",
      "Val:  [1250/1416]  eta: 0:01:12  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7706)  bal_acc: 0.5000 (0.3853)  pod: 0.0000 (0.0232)  far: 0.0000 (0.2286)  time: 0.3932 (0.3921 -- 0.3945)  data: 0.0002 (0.0001 -- 0.0006)  max mem: 4528\n",
      "Val:  [1260/1416]  eta: 0:01:08  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7724)  bal_acc: 0.5000 (0.3862)  pod: 0.0000 (0.0230)  far: 0.0000 (0.2268)  time: 0.3933 (0.3922 -- 0.3950)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1270/1416]  eta: 0:01:03  loss: 0.6920 (0.6926)  acc: 1.0000 (0.7742)  bal_acc: 0.5000 (0.3871)  pod: 0.0000 (0.0228)  far: 0.0000 (0.2250)  time: 0.3932 (0.3922 -- 0.3950)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [1280/1416]  eta: 0:00:59  loss: 0.6920 (0.6926)  acc: 1.0000 (0.7760)  bal_acc: 0.5000 (0.3880)  pod: 0.0000 (0.0226)  far: 0.0000 (0.2233)  time: 0.3932 (0.3923 -- 0.3942)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [1290/1416]  eta: 0:00:54  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7777)  bal_acc: 0.5000 (0.3888)  pod: 0.0000 (0.0225)  far: 0.0000 (0.2215)  time: 0.3932 (0.3923 -- 0.3944)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1300/1416]  eta: 0:00:50  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7794)  bal_acc: 0.5000 (0.3897)  pod: 0.0000 (0.0223)  far: 0.0000 (0.2198)  time: 0.3933 (0.3923 -- 0.3946)  data: 0.0002 (0.0001 -- 0.0011)  max mem: 4528\n",
      "Val:  [1310/1416]  eta: 0:00:46  loss: 0.6920 (0.6926)  acc: 1.0000 (0.7811)  bal_acc: 0.5000 (0.3905)  pod: 0.0000 (0.0221)  far: 0.0000 (0.2182)  time: 0.3929 (0.3921 -- 0.3946)  data: 0.0002 (0.0001 -- 0.0011)  max mem: 4528\n",
      "Val:  [1320/1416]  eta: 0:00:41  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7827)  bal_acc: 0.5000 (0.3914)  pod: 0.0000 (0.0220)  far: 0.0000 (0.2165)  time: 0.3926 (0.3921 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [1330/1416]  eta: 0:00:37  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7844)  bal_acc: 0.5000 (0.3922)  pod: 0.0000 (0.0218)  far: 0.0000 (0.2149)  time: 0.3926 (0.3919 -- 0.3932)  data: 0.0001 (0.0001 -- 0.0003)  max mem: 4528\n",
      "Val:  [1340/1416]  eta: 0:00:32  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7860)  bal_acc: 0.5000 (0.3930)  pod: 0.0000 (0.0216)  far: 0.0000 (0.2133)  time: 0.3925 (0.3916 -- 0.3939)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1350/1416]  eta: 0:00:28  loss: 0.6921 (0.6926)  acc: 1.0000 (0.7876)  bal_acc: 0.5000 (0.3938)  pod: 0.0000 (0.0215)  far: 0.0000 (0.2117)  time: 0.3924 (0.3916 -- 0.3939)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1360/1416]  eta: 0:00:24  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7891)  bal_acc: 0.5000 (0.3946)  pod: 0.0000 (0.0213)  far: 0.0000 (0.2101)  time: 0.3924 (0.3917 -- 0.3935)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1370/1416]  eta: 0:00:19  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7907)  bal_acc: 0.5000 (0.3953)  pod: 0.0000 (0.0212)  far: 0.0000 (0.2086)  time: 0.3923 (0.3918 -- 0.3930)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1380/1416]  eta: 0:00:15  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7922)  bal_acc: 0.5000 (0.3961)  pod: 0.0000 (0.0210)  far: 0.0000 (0.2071)  time: 0.3923 (0.3915 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1390/1416]  eta: 0:00:11  loss: 0.6922 (0.6926)  acc: 1.0000 (0.7937)  bal_acc: 0.5000 (0.3968)  pod: 0.0000 (0.0208)  far: 0.0000 (0.2056)  time: 0.3922 (0.3907 -- 0.3931)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1400/1416]  eta: 0:00:06  loss: 0.6922 (0.6925)  acc: 1.0000 (0.7951)  bal_acc: 0.5000 (0.3976)  pod: 0.0000 (0.0207)  far: 0.0000 (0.2041)  time: 0.3920 (0.3907 -- 0.3928)  data: 0.0001 (0.0001 -- 0.0001)  max mem: 4528\n",
      "Val:  [1410/1416]  eta: 0:00:02  loss: 0.6922 (0.6925)  acc: 1.0000 (0.7966)  bal_acc: 0.5000 (0.3983)  pod: 0.0000 (0.0206)  far: 0.0000 (0.2027)  time: 0.3918 (0.3908 -- 0.3928)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val:  [1415/1416]  eta: 0:00:00  loss: 0.6922 (0.6925)  acc: 1.0000 (0.7973)  bal_acc: 0.5000 (0.3987)  pod: 0.0000 (0.0205)  far: 0.0000 (0.2020)  time: 0.3917 (0.3908 -- 0.3925)  data: 0.0001 (0.0001 -- 0.0002)  max mem: 4528\n",
      "Val: Total time: 0:10:11 (0.4318 s / it)\n",
      "* Balanced Acc@1 0.880  loss 0.693\n",
      "[all] salvato output/inference_predictions_all.csv - bal_acc=0.8801587301587301\n"
     ]
    }
   ],
   "source": [
    "# inferenza come inference_classification.py (salva CSV predictions)\n",
    "from engine_for_finetuning import validation_one_epoch_collect\n",
    "\n",
    "# usa gli stessi args/model caricati sopra\n",
    "try:\n",
    "    _ = model\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Modello non trovato: esegui prima la cella di caricamento del modello\")\n",
    "\n",
    "try:\n",
    "    _ = args\n",
    "except NameError:\n",
    "    args = prepare_finetuning_args()\n",
    "\n",
    "# se non hai creato 'datasets' sopra, usa il csv_file corrente\n",
    "if 'datasets' not in globals():\n",
    "    datasets = [{'name': 'single', 'csv': csv_file}]\n",
    "\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "for d in datasets:\n",
    "    csv_path = d.get('csv')\n",
    "    name = d.get('name','dataset')\n",
    "    if not csv_path:\n",
    "        print(f\"[{name}] csv non definito\")\n",
    "        continue\n",
    "    print(f\"[{name}] inferenza su {csv_path}\")\n",
    "\n",
    "    args.val_path = csv_path\n",
    "    val_m = DataManager(is_train=False, args=args, type_t='supervised', world_size=1, rank=0, specify_data_path=args.val_path)\n",
    "    val_m.create_classif_dataloader(args)\n",
    "\n",
    "    model.eval()\n",
    "    val_stats, all_paths, all_preds, all_labels = validation_one_epoch_collect(val_m.data_loader, model, args.device)\n",
    "\n",
    "    df_predictions = create_df_predictions(all_paths, all_preds, all_labels)\n",
    "    out_csv = Path('output') / f\"inference_predictions_{name}.csv\"\n",
    "    df_predictions.to_csv(out_csv, index=False)\n",
    "    print(f\"[{name}] salvato {out_csv} - bal_acc={val_stats.get('bal_acc')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH aggiornato con ffmpeg-7.0.2-amd64-static\n"
     ]
    }
   ],
   "source": [
    "# Assicura che ffmpeg sia nel PATH (se hai la build locale)\n",
    "ffmpeg_local = Path('./ffmpeg-7.0.2-amd64-static')\n",
    "if ffmpeg_local.exists():\n",
    "    os.environ['PATH'] = str(ffmpeg_local) + os.pathsep + os.environ.get('PATH', '')\n",
    "    print(f\"PATH aggiornato con {ffmpeg_local}\")\n",
    "else:\n",
    "    print(\"ffmpeg locale non trovato: assicurati che ffmpeg sia nel PATH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Generazione dei frame PNG in anim_frames_mediterraneo_all\n",
      " abbiamo 328 gruppi\n",
      "Tutti i frame sono stati generati\n",
      "0.05 minuti\n",
      "\n",
      ">>> Creazione del video MP4 con ffmpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, concat, from 'anim_frames_mediterraneo_all/frames.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc, gbr/unknown/unknown), 1290x420 [SAR 3780:3780 DAR 43:14], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x21647800] using SAR=1/1\n",
      "[libx264 @ 0x21647800] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x21647800] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x21647800] 264 - core 164 r3191 4613ac3 - H.264/MPEG-4 AVC codec - Copyleft 2003-2024 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=13 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'mediterraneo_all.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1290x420 [SAR 1:1 DAR 43:14], q=2-31, 25 fps, 12800 tbn\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/mp4 @ 0x21646400] video:20200KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.027658%\n",
      "frame=  329 fps= 53 q=-1.0 Lsize=   20206KiB time=00:00:32.64 bitrate=5071.2kbits/s speed=5.26x    \n",
      "[libx264 @ 0x21647800] frame I:2     Avg QP:17.00  size:196688\n",
      "[libx264 @ 0x21647800] frame P:275   Avg QP:18.29  size: 68303\n",
      "[libx264 @ 0x21647800] frame B:52    Avg QP:21.23  size: 28987\n",
      "[libx264 @ 0x21647800] consecutive B-frames: 78.7%  0.6%  0.0% 20.7%\n",
      "[libx264 @ 0x21647800] mb I  I16..4:  4.2% 22.4% 73.5%\n",
      "[libx264 @ 0x21647800] mb P  I16..4:  0.2%  0.7%  0.6%  P16..4: 30.0% 31.2% 32.7%  0.0%  0.0%    skip: 4.6%\n",
      "[libx264 @ 0x21647800] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 19.5% 14.1%  9.9%  direct:21.8%  skip:34.7%  L0:13.1% L1:27.7% BI:59.1%\n",
      "[libx264 @ 0x21647800] 8x8 transform intra:38.0% inter:43.5%\n",
      "[libx264 @ 0x21647800] coded y,uvDC,uvAC intra: 77.1% 84.5% 82.9% inter: 69.3% 78.9% 57.2%\n",
      "[libx264 @ 0x21647800] i16 v,h,dc,p: 56% 27%  6% 11%\n",
      "[libx264 @ 0x21647800] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 21% 12%  5%  6%  5%  7%  5% 11%\n",
      "[libx264 @ 0x21647800] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 20% 10%  6%  7%  7%  9%  6% 10%\n",
      "[libx264 @ 0x21647800] i8c dc,h,v,p: 47% 24% 14% 16%\n",
      "[libx264 @ 0x21647800] Weighted P-Frames: Y:2.9% UV:1.5%\n",
      "[libx264 @ 0x21647800] ref P L0: 72.1% 23.8%  2.9%  1.0%  0.2%\n",
      "[libx264 @ 0x21647800] ref B L0: 95.1%  3.8%  1.2%\n",
      "[libx264 @ 0x21647800] ref B L1: 99.6%  0.4%\n",
      "[libx264 @ 0x21647800] kb/s:5032.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video salvato: mediterraneo_all.mp4\n",
      "\n",
      "Cartella anim_frames_mediterraneo_all già esistente, non ricreo i frame. Controlla se il video è già stato creato.\n",
      "Video già esistente: mediterraneo_all.mp4\n"
     ]
    }
   ],
   "source": [
    "# Dopo aver eseguito l'inferenza (inference_classification.py) con i CSV generati sopra,\n",
    "# imposta qui i percorsi dei CSV di predizione.\n",
    "\n",
    "from dataset.build_dataset import calc_tile_offsets\n",
    "from view_test_tiles import expand_group, make_animation_parallel_ffmpeg\n",
    "\n",
    "# Mappa nome-dataset -> CSV delle predizioni (da inference_classification.py)\n",
    "# Esempio: {\"all\": \"output/inference_predictions.csv\"}\n",
    "preds_csv_map = {\n",
    "    'all': 'output/inference_predictions.csv',\n",
    "}\n",
    "\n",
    "for d in datasets:\n",
    "    preds_csv = preds_csv_map.get(d['name'])\n",
    "    if not preds_csv or not Path(preds_csv).exists():\n",
    "        print(f\"[{d['name']}] preds csv non trovato: {preds_csv}\")\n",
    "        continue\n",
    "\n",
    "    df_predictions = pd.read_csv(preds_csv)\n",
    "    df_video_w_predictions = d['builder'].df_video.merge(df_predictions, on='path')\n",
    "\n",
    "    # mappa video -> immagini\n",
    "    df_mapping = video_pred_2_img_pred(df_video_w_predictions)\n",
    "\n",
    "    # merge con master_df per avere le coordinate\n",
    "    df_data_merg = df_mapping.merge(\n",
    "        d['builder'].master_df,\n",
    "        on=['path', 'tile_offset_x', 'tile_offset_y'],\n",
    "        how='left'\n",
    "    ).drop(columns='label').rename(columns={'tmp_label': 'label'})\n",
    "\n",
    "    # espansione con tile mancanti (per coprire l'intero Mediterraneo)\n",
    "    offsets = calc_tile_offsets(stride_x=213, stride_y=196)\n",
    "    df_offsets = pd.DataFrame(offsets, columns=['tile_offset_x', 'tile_offset_y'])\n",
    "    expanded_df = df_data_merg.groupby('path', group_keys=False).apply(\n",
    "        lambda g: expand_group(g, df_offsets)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    expanded_df.predictions = expanded_df.predictions.astype('Int8')\n",
    "    expanded_df.label = expanded_df.label.astype('Int8')\n",
    "\n",
    "    nomefile = f\"mediterraneo_{d['name']}\"\n",
    "    make_animation_parallel_ffmpeg(expanded_df, nomefile=nomefile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parto da un dataset già salvato di cui ho il csv (e i video salvati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### come sopra, e non devo saltare il Build_Dataset perché il master_df mi serve comunque (quello identico con cui ho salvato il csv) per generare il df_video da cui prendere gli orig_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) (20,)\n",
      "(1580, 9) (1817, 9)\n"
     ]
    }
   ],
   "source": [
    "tracks_df_MED_CL10 = pd.read_csv(\"manos_CL10_pixel.csv\", parse_dates=['time', 'start_time', 'end_time'])\n",
    "# divido le track di Manos in train e test\n",
    "cicloni_unici = tracks_df_MED_CL10.id_cyc_unico.unique()\n",
    "train_p = 0.7\n",
    "len_p = int(train_p*cicloni_unici.shape[0])\n",
    "cicloni_unici_train = cicloni_unici[:len_p]\n",
    "cicloni_unici_test = cicloni_unici[len_p:]\n",
    "print(cicloni_unici_train.shape, cicloni_unici_test.shape)\n",
    "tracks_df_train = tracks_df_MED_CL10[tracks_df_MED_CL10.id_cyc_unico.isin(cicloni_unici_train)]\n",
    "tracks_df_test = tracks_df_MED_CL10[tracks_df_MED_CL10.id_cyc_unico.isin(cicloni_unici_test)]\n",
    "print(tracks_df_train.shape, tracks_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_m = BuildDataset(type='SUPERVISED')\n",
    "train_m.get_data_ready(tracks_df_train, input_dir, output_dir, csv_file=\"train_CL10\")\n",
    "#test_m = BuildDataset(type='SUPERVISED')\n",
    "#test_m.get_data_ready(tracks_df_test, input_dir, output_dir, csv_file=\"test_CL10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m.df_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " abbiamo 8064 gruppi\n",
      "34.21 minuti\n",
      "Video salvato: testset_CL10_148.mp4\n"
     ]
    }
   ],
   "source": [
    "# realizzo il video di sole label\n",
    "from view_test_tiles import filter_on_intervals\n",
    "cl10_intervals = tracks_df_train.groupby('id_cyc_unico').agg({'start_time':'first', 'end_time':'first'})\n",
    "\n",
    "filtered_df1 = filter_on_intervals(cl10_intervals, train_m.master_df)\n",
    "ffmpegwriter=get_writer4animation('./ffmpeg-7.0.2-amd64-static:')\n",
    "make_animation(filtered_df1, nomefile='testset_CL10_148.mp4', writer=ffmpegwriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (213, 0),\n",
       " (426, 0),\n",
       " (639, 0),\n",
       " (852, 0),\n",
       " (1065, 0),\n",
       " (0, 196),\n",
       " (213, 196),\n",
       " (426, 196),\n",
       " (639, 196),\n",
       " (852, 196),\n",
       " (1065, 196)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from view_test_tiles import calc_tile_offsets\n",
    "offsets = calc_tile_offsets(stride_x=213, stride_y=196)\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset...\n",
      "DATASET length: 148\n",
      "Creo il DistributedSampler con world_size 1 e rank 0\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f58f3b0b130>\n",
      "Batch_size: 1\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"./train_CL10_148.csv\"  # il train era venuto più piccolo del test, uso questo più piccolo come test\n",
    "\n",
    "args = prepare_finetuning_args()\n",
    "args.test_path = csv_file\n",
    "\n",
    "test_datam = DataManager(is_train=False, args=args, type_t='supervised', world_size=1, rank=0)\n",
    "test_datam.create_classif_dataloader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### caricol il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction = True\n",
    "args.test_mode = True\n",
    "args.init_ckpt = './output/checkpoint-best-CL10.pth'\n",
    "\n",
    "model = create_model(\n",
    "    args.model,\n",
    "    num_classes=args.nb_classes,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=args.drop_path,\n",
    "    #attn_drop_rate=0.0,\n",
    "    drop_block_rate=None,\n",
    "    **args.__dict__\n",
    ")\n",
    "\n",
    "model.to(args.device)\n",
    "model.eval()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ottengo il dataframe delle predizioni e riporto le predizioni al master df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths, all_preds, all_labels = get_path_pred_label(model, test_datam.data_loader)\n",
    "df_predictions = create_df_predictions(all_paths, all_preds, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in r4ealtà non è un train_m ma un test_m  (TODO: cambiare nome all'istanza in modo che sia più simile alla classe)\n",
    "df_video_w_predictions = train_m.df_video.merge(df_predictions, on='path')   \n",
    "\n",
    "df_mapping = video_pred_2_img_pred(df_video_w_predictions)\n",
    "\n",
    "# se voglio limitare i frame da renderizzare\n",
    "#df_sub = sub_select_frequency(train_m.master_df)\n",
    "\n",
    "# ottengo il dataframe di immagini per creare il video MED: \n",
    "######### ????uso df_sub quì??? (al posto di train_m.master_df)\n",
    "df_data_merg = df_mapping.merge(train_m.master_df, on=['path', 'tile_offset_x', 'tile_offset_y'], how='left').drop(columns='label').rename(columns={'tmp_label':'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ora gestisco il caso in cui parto da un dataset dove non ho tutte le tile del mediterraneo (come quasi sempre nel training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offsets = train_m.master_df[['tile_offset_x','tile_offset_y']].value_counts().reset_index().drop(columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanded_df = df_data_merg.groupby('path', group_keys=False).apply(expand_group).reset_index(drop=True)\n",
    "\n",
    "expanded_df = df_data_merg.groupby('path', group_keys=False).apply(lambda x: expand_group(x, df_offsets)).reset_index(drop=True)\n",
    "expanded_df.predictions = expanded_df.predictions.astype('Int8')\n",
    "expanded_df.label = expanded_df.label.astype('Int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <NA>\n",
       "1        <NA>\n",
       "2        <NA>\n",
       "3        <NA>\n",
       "4        <NA>\n",
       "         ... \n",
       "19783    <NA>\n",
       "19784    <NA>\n",
       "19785    <NA>\n",
       "19786    <NA>\n",
       "19787    <NA>\n",
       "Name: predictions, Length: 19788, dtype: Int8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df.predictions.astype('Int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creazione video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " abbiamo 1649 gruppi\n",
      "7.09 minuti\n",
      "Video salvato: testset_CL10_148_pred_.mp4\n"
     ]
    }
   ],
   "source": [
    "ffmpegwriter=get_writer4animation('./ffmpeg-7.0.2-amd64-static:')\n",
    "make_animation(expanded_df, nomefile='testset_CL10_148_pred_.mp4', writer=ffmpegwriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
