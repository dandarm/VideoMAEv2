{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galleria rapida delle tracce\n",
    "\n",
    "Notebook derivato da `View_tracking_tiles` per effettuare una revisione visiva del dataset di tracking.\n",
    "Consente di sfogliare più clip contemporaneamente e di annotare velocemente quelle da conservare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from arguments import prepare_finetuning_args\n",
    "from dataset.data_manager import BuildTrackingDataset, DataManager\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.datasets import MedicanesTrackDataset\n",
    "from dataset.build_dataset import get_cyclone_center_pixel\n",
    "from view_test_tiles import display_video_clip\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from typing import Sequence, List, Optional, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = prepare_finetuning_args()\n",
    "\n",
    "# Percorsi\n",
    "input_dir = \"../fromgcloud\"\n",
    "output_dir = \"../airmassRGB/supervised/\"\n",
    "csv_out = \"train_tracking.csv\"          # CSV finale con pixel per tracking\n",
    "manos_file = \"medicane_data_input/more_medicanes_time_updated.csv\"\n",
    "df_tracks = pd.read_csv(manos_file, parse_dates=['time', 'start_time', 'end_time'])\n",
    "\n",
    "bt = BuildTrackingDataset(type=\"supervised\", args=args)\n",
    "bt.prepare_data(df_tracks, input_dir, output_dir)\n",
    "bt.create_tracking_csv(output_dir, csv_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costruisce DataLoader per tracking a partire dal CSV generato\n",
    "dm = DataManager(is_train=False, args=args, type_t='supervised', specify_data_path=csv_out)\n",
    "track_loader = dm.get_tracking_dataloader(args)\n",
    "track_ds = dm.dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selezione simultanea di più clip\n",
    "\n",
    "La classe seguente crea una galleria di clip video con pulsanti \"toggle\" per selezionare le tracce da mantenere.\n",
    "Gli identificativi selezionati (indici o path) possono poi essere salvati e riutilizzati per filtrare il DataFrame del CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGallerySelector:\n",
    "    \"\"\"Galleria interattiva per selezionare clip di tracking.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        clips: Sequence[Sequence[np.ndarray]],\n",
    "        identifiers: Optional[Sequence[Any]] = None,\n",
    "        columns: int = 3,\n",
    "        interval: int = 200,\n",
    "        toggle_icon: str = 'check'\n",
    "    ) -> None:\n",
    "        if identifiers is None:\n",
    "            identifiers = list(range(len(clips)))\n",
    "        if len(identifiers) != len(clips):\n",
    "            raise ValueError('`identifiers` deve avere la stessa lunghezza di `clips`.')\n",
    "\n",
    "        self.clips = clips\n",
    "        self.identifiers = list(identifiers)\n",
    "        self.columns = max(1, int(columns))\n",
    "        self.interval = interval\n",
    "        self.toggle_icon = toggle_icon\n",
    "\n",
    "        self._toggles: List[widgets.ToggleButton] = []\n",
    "        self._container = self._build_widget()\n",
    "\n",
    "    def _build_widget(self) -> widgets.Widget:\n",
    "        cards: List[widgets.Widget] = []\n",
    "        grid_columns = min(self.columns, len(self.clips)) or 1\n",
    "        column_template = f'repeat({grid_columns}, minmax(0, 1fr))'\n",
    "\n",
    "        for idx, (clip, ident) in enumerate(zip(self.clips, self.identifiers)):\n",
    "            output = widgets.Output(layout=widgets.Layout(width='100%'))\n",
    "            with output:\n",
    "                display(display_video_clip(clip, interval=self.interval))\n",
    "\n",
    "            toggle = widgets.ToggleButton(\n",
    "                value=False,\n",
    "                description=str(ident),\n",
    "                icon=self.toggle_icon,\n",
    "                layout=widgets.Layout(width='100%')\n",
    "            )\n",
    "            toggle.observe(self._on_toggle_change, names='value')\n",
    "            self._toggles.append(toggle)\n",
    "\n",
    "            cards.append(\n",
    "                widgets.VBox(\n",
    "                    [output, toggle],\n",
    "                    layout=widgets.Layout(\n",
    "                        border='1px solid #ccc',\n",
    "                        padding='6px',\n",
    "                        align_items='stretch'\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        grid = widgets.GridBox(\n",
    "            cards,\n",
    "            layout=widgets.Layout(\n",
    "                grid_template_columns=column_template,\n",
    "                grid_gap='12px',\n",
    "                width='100%'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self._selection_label = widgets.HTML()\n",
    "        self._update_selection_label()\n",
    "\n",
    "        return widgets.VBox([\n",
    "            grid,\n",
    "            self._selection_label\n",
    "        ], layout=widgets.Layout(width='100%'))\n",
    "\n",
    "    def _on_toggle_change(self, change):\n",
    "        if change.get('name') == 'value':\n",
    "            self._update_selection_label()\n",
    "\n",
    "    def _update_selection_label(self) -> None:\n",
    "        chosen = self.get_selected_identifiers()\n",
    "        if chosen:\n",
    "            values = ', '.join(map(str, chosen))\n",
    "            self._selection_label.value = f\"<b>Selezionati:</b> {values}\"\n",
    "        else:\n",
    "            self._selection_label.value = '<i>Nessun video selezionato</i>'\n",
    "\n",
    "    @property\n",
    "    def widget(self) -> widgets.Widget:\n",
    "        \"\"\"Restituisce il contenitore principale da visualizzare nel notebook.\"\"\"\n",
    "        return self._container\n",
    "\n",
    "    def display(self) -> None:\n",
    "        \"\"\"Visualizza la galleria nel notebook.\"\"\"\n",
    "        display(self._container)\n",
    "\n",
    "    def get_selected_indices(self) -> List[int]:\n",
    "        \"\"\"Ritorna la lista degli indici (relativi alla galleria) selezionati.\"\"\"\n",
    "        return [idx for idx, toggle in enumerate(self._toggles) if toggle.value]\n",
    "\n",
    "    def get_selected_identifiers(self) -> List[Any]:\n",
    "        \"\"\"Ritorna la lista degli identificativi associati alle clip selezionate.\"\"\"\n",
    "        indices = self.get_selected_indices()\n",
    "        return [self.identifiers[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrae alcune clip dal dataset per popolare la galleria\n",
    "max_samples = 6\n",
    "sample_indices = list(range(max_samples))\n",
    "\n",
    "clips = []\n",
    "identifiers = []\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1, 1)\n",
    "\n",
    "for ds_idx in sample_indices:\n",
    "    video, coords, folder = track_ds[ds_idx]\n",
    "    video = (video * std + mean).clamp(0, 1)\n",
    "\n",
    "    frames = []\n",
    "    for frame in video.permute(1, 2, 3, 0).cpu().numpy():\n",
    "        frames.append(np.clip(frame, 0.0, 1.0))\n",
    "    clips.append(frames)\n",
    "\n",
    "    # Usa il path della cartella come identificativo per poterlo incrociare con il CSV\n",
    "    identifiers.append(folder)\n",
    "\n",
    "selector = VideoGallerySelector(clips, identifiers=identifiers, columns=3, interval=200)\n",
    "selector.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera gli identificativi (es. path cartella) delle clip marcate\n",
    "selezionati = selector.get_selected_identifiers()\n",
    "selezionati\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso con il DataFrame del CSV\n",
    "\n",
    "Gli identificativi ottenuti possono essere utilizzati per filtrare il CSV originale.\n",
    "Ad esempio, se il path della cartella è presente in una colonna `folder`, si può eseguire:\n",
    "\n",
    "```python\n",
    "df_tracking = pd.read_csv(csv_out)\n",
    "df_selezionati = df_tracking[df_tracking['folder'].isin(selezionati)]\n",
    "```\n",
    "\n",
    "In alternativa è possibile memorizzare gli indici relativi della galleria tramite\n",
    "`selector.get_selected_indices()` e unirli con l'indice del DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}