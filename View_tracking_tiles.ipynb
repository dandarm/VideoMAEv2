{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize tracking dataset\n",
        "\n",
        "Load a sample from `MedicanesTrackDataset` and overlay the cyclone centre on the video tile.\n",
        "\n",
        "Set `csv_path` and `data_root` to point to your local data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Impossibile caricare la libreria torch dynamo\n"
          ]
        }
      ],
      "source": [
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from arguments import prepare_finetuning_args\n",
        "from dataset.data_manager import BuildTrackingDataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset.tracking_dataset import MedicanesTrackDataset\n",
        "from dataset.build_dataset import get_cyclone_center_pixel\n",
        "from view_test_tiles import display_video_clip\n",
        "from PIL import Image, ImageDraw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "CSV must contain columns 'lon' and 'lat' for coordinates",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m data_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATH/TO/tiles\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create dataset and loader\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m track_ds \u001b[38;5;241m=\u001b[39m \u001b[43mMedicanesTrackDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(track_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/media/isacDisk1/VideoMAEv2/dataset/tracking_dataset.py:49\u001b[0m, in \u001b[0;36mMedicanesTrackDataset.__init__\u001b[0;34m(self, anno_path, data_root, clip_len, transform, lon_col, lat_col)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Columns containing the coordinates of the last frame\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lon_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m lat_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV must contain columns \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for coordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlon_col \u001b[38;5;241m=\u001b[39m lon_col\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlat_col \u001b[38;5;241m=\u001b[39m lat_col\n",
            "\u001b[0;31mValueError\u001b[0m: CSV must contain columns 'lon' and 'lat' for coordinates"
          ]
        }
      ],
      "source": [
        "# Paths to the annotation CSV and tile frames\n",
        "csv_path = 'output/traintest_csv/train_manos_w_1238.csv'\n",
        "data_root = 'PATH/TO/tiles'\n",
        "args = prepare_finetuning_args()\n",
        "\n",
        "\n",
        "# Percorsi\n",
        "input_dir = \"/path/alle/immagini/\"      # cartella immagini grandi\n",
        "output_dir = \"/path/tiles/\"             # cartella dove vengono salvate le tile 224Ã—224 (con sottocartelle)\n",
        "csv_out = \"train_tracking.csv\"          # CSV finale con pixel per tracking\n",
        "tracks_df = pd.read_csv(\"manos_tracks.csv\", parse_dates=['time', 'start_time', 'end_time'])\n",
        "\n",
        "# Create dataset and loader\n",
        "track_ds = MedicanesTrackDataset(csv_path, data_root=\"./\")\n",
        "loader = DataLoader(track_ds, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_offsets(folder_path: str):\n",
        "    \"\"\"Parse tile top-left corner (x, y) from folder name.\"\"\"\n",
        "    base = os.path.basename(folder_path.rstrip(os.sep))\n",
        "    nums = [int(n) for n in re.findall(r'\\d+', base)]\n",
        "    if len(nums) >= 2:\n",
        "        return nums[-2], nums[-1]\n",
        "    return 0, 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grab a single example\n",
        "video, coords, folder = track_ds[0]\n",
        "\n",
        "# Undo normalization to [0, 1]\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1,1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1,1)\n",
        "video = (video * std + mean).clamp(0, 1)\n",
        "\n",
        "# Convert to numpy [T, H, W, C]\n",
        "video_np = video.permute(1, 2, 3, 0).numpy()\n",
        "\n",
        "# Convert geographic coords to pixel position in the big frame\n",
        "lon, lat = coords.tolist()\n",
        "px, py = get_cyclone_center_pixel(lat, lon)\n",
        "\n",
        "# Extract tile offset from folder path and compute position in the tile\n",
        "x_off, y_off = extract_offsets(folder)\n",
        "px_tile = px - x_off\n",
        "py_tile = py - y_off\n",
        "\n",
        "# Draw the cyclone centre on each frame\n",
        "frames = []\n",
        "for frame in video_np:\n",
        "    img = (frame * 255).astype(np.uint8)\n",
        "    pil = Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(pil)\n",
        "    r = 4\n",
        "    draw.ellipse((px_tile - r, py_tile - r, px_tile + r, py_tile + r), fill=(255, 0, 0))\n",
        "    frames.append(np.asarray(pil) / 255.0)\n",
        "\n",
        "# Display the clip\n",
        "display_video_clip(frames)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "videomae",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
